# ü§ñ LLM Context Guide for RoboMage

This guide helps AI assistants quickly understand the RoboMage project structure and context.

**Essential Files to Read First

**Core Architecture & API:**
1. `README.md` - Project overview, API documentation, and usage examples
2. `src/robomage/__init__.py` - Main package API and public interface
3. `src/robomage/data/models.py` - Core data structures (DiffractionData, DataStatistics)
4. `src/robomage/data/loaders.py` - File loading and format detection
5. `pixi.toml` - Environment configuration and available tasks

**Project Configuration:**
6. `pyproject.toml` - Python package configuration, dependencies, tool settings
7. `docs/README_full.md` - Detailed architecture and future vision

**Examples & Tests:**
8. `examples/load_data_example.py` - Comprehensive tutorial showing both APIs
9. `tests/test_data_models.py` - Core functionality tests and expected behavior
10. `src/robomage/__main__.py` - CLI implementation and command-line interface

## üèóÔ∏è Project Architecture Summary

**Language & Environment:** Python 3.10+ with Pixi environment management  
**Core Framework:** Pydantic v2 for data validation, NumPy/Pandas for scientific computing  
**Code Quality:** Ruff (formatting/linting), MyPy (type checking), Pytest (testing)  

**Dual API Design:**
- **Modern API**: `robomage.load_diffraction_file()` ‚Üí `DiffractionData` (Pydantic models)
- **Legacy API**: `robomage.data_io.load_test_data()` ‚Üí `pandas.DataFrame`
  - Also available as: `robomage.load_test_data_df()`, `robomage.load_chi_file_df()`, `robomage.get_data_info()`

**Key Components:**
- **Data Loading**: Auto-detection of .chi files with validation
- **Data Models**: Type-safe Pydantic classes with computed properties
- **CLI Interface**: `python -m robomage` for batch processing and visualization
- **Statistics**: Built-in quality metrics and data summarization
- **Dual API**: Modern Pydantic models + legacy pandas DataFrame compatibility

## üéØ Current Status (Week 2 Complete)

**Implemented & Working:**
‚úÖ Robust data loading and validation system  
‚úÖ Modern Pydantic-based data models with statistical analysis  
‚úÖ Command-line interface for batch processing  
‚úÖ Comprehensive documentation and examples  
‚úÖ Full test coverage (20 tests passing)  
‚úÖ Type-safe codebase with MyPy compliance  

**Future Development (Planned):**
üîÑ GSAS-II integration for automated Rietveld refinement  
üîÑ Advanced data pipeline with Tiled/Databroker integration  
üîÑ Web interface and workflow automation  
üîÑ Machine learning-guided parameter optimization  

## üõ†Ô∏è Development Patterns

**Code Style:**
- Use Pydantic models for new data structures
- Include comprehensive docstrings with examples
- Maintain both modern and legacy API compatibility
- Follow scientific Python conventions (Q for momentum transfer, etc.)

**Testing:**
- Test files match pattern `test_*.py` in `tests/` directory
- Use pytest with parametrization for multiple test cases
- Include both unit tests and integration examples
- Current test coverage: 20 tests across 4 files:
  - `test_data_models.py` (8 tests) - Core data structure functionality
  - `test_data_loaders.py` (6 tests) - File loading and validation
  - `test_data_io.py` (5 tests) - Legacy API compatibility
  - `test_schema.py` (1 test) - Configuration schema validation

**Common Tasks:**
```bash
pixi run test      # Run full test suite (pytest -q)
pixi run lint      # Check code style (ruff check .)
pixi run format    # Auto-format code (ruff format .)
pixi run typecheck # Type checking (mypy src)
pixi run check     # Run all checks (format-check, lint, typecheck, test)
```

## üìä Key Data Structures

**DiffractionData** (Modern API):
```python
data = robomage.load_diffraction_file("sample.chi")
data.q_values          # NumPy array of Q values (√Ö‚Åª¬π)
data.intensity_values  # NumPy array of intensities
data.statistics        # DataStatistics with computed properties
data.trim_q_range(2,8) # Filter by Q range
data.to_dataframe()    # Convert to pandas DataFrame
```

**DataStatistics** (Computed Properties):
```python
stats = data.statistics
stats.q_range          # (min, max) Q values (tuple)
stats.num_points       # Number of data points
stats.intensity_mean   # Mean intensity
stats.intensity_std    # Standard deviation of intensities
stats.q_step_mean      # Average Q step size
stats.q_step_std       # Standard deviation of Q step size
stats.intensity_range  # (min, max) intensity values (tuple)
```

## üö® Important Context Notes

1. **File Formats**: Currently supports .chi files (two-column: Q, intensity)
2. **Test Data**: Built-in SRM 660b LaB‚ÇÜ standard available via `load_test_data()`
3. **Validation**: Automatic Q-value sorting and NaN/inf detection
4. **Error Handling**: Comprehensive with clear scientific error messages
5. **Configuration**: Placeholder config system exists (`src/robomage/config/`) but not fully implemented yet
6. **Visualization**: Basic matplotlib integration; visualization.py module exists but is empty
7. **Version**: Currently 0.0.1 (development), may show as 0.1.0-dev in __init__.py
8. **Module Structure**: 
   - `src/robomage/data/` - Core data handling (models, loaders)
   - `src/robomage/config/` - Configuration schemas (placeholder)
   - `src/robomage/data_io.py` - Legacy pandas-based API
   - `src/robomage/__main__.py` - CLI implementation
   - `src/robomage/visualization.py` - Empty placeholder for future plotting utilities
   - `src/robomage/orchestrator.py` - Placeholder for workflow management

## üîç Debugging Tips

- Check `pixi run test` for current functionality status (should show 20 tests passing)
- Use `examples/load_data_example.py` to understand expected behavior
- Look at `tests/` directory for edge cases and expected error handling
- All public APIs are documented in respective `__init__.py` files
- CLI functionality: `pixi run python -m robomage --help` shows all available options
- Data validation: Most errors are caught by Pydantic models with clear messages
- Legacy API issues: Check `src/robomage/data_io.py` for pandas-based workflows

## üìù Documentation Standards

- Include scientific context (powder diffraction, momentum transfer Q)
- Provide working code examples in docstrings
- Explain both modern and legacy usage patterns
- Reference test data (SRM 660b) in examples
- Use proper units (√Ö‚Åª¬π for Q, arbitrary units for intensity)

---

**Last Updated:** October 21, 2025  
**Project Status:** Week 2 Complete - Production-ready data pipeline with comprehensive documentation